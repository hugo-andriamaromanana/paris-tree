{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200137 entries, 0 to 200136\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   id                   200137 non-null  int64  \n",
      " 1   type_emplacement     200137 non-null  object \n",
      " 2   domanialite          200136 non-null  object \n",
      " 3   arrondissement       200137 non-null  object \n",
      " 4   complement_addresse  30902 non-null   object \n",
      " 5   numero               0 non-null       float64\n",
      " 6   lieu                 200137 non-null  object \n",
      " 7   id_emplacement       200137 non-null  object \n",
      " 8   libelle_francais     198640 non-null  object \n",
      " 9   genre                200121 non-null  object \n",
      " 10  espece               198385 non-null  object \n",
      " 11  variete              36777 non-null   object \n",
      " 12  circonference_cm     200137 non-null  int64  \n",
      " 13  hauteur_m            200137 non-null  int64  \n",
      " 14  stade_developpement  132932 non-null  object \n",
      " 15  remarquable          137039 non-null  float64\n",
      " 16  geo_point_2d_a       200137 non-null  float64\n",
      " 17  geo_point_2d_b       200137 non-null  float64\n",
      "dtypes: float64(4), int64(3), object(11)\n",
      "memory usage: 27.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path.join(\"..\",\"data/raw\",\"paris_threes_raw.csv\"), sep=\";\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = [col for col in df.columns if col not in [\"circonference_cm\", \"hauteur_m\", \"remarquable\"]]\n",
    "df.dropna(subset=[\"remarquable\"], inplace=True)\n",
    "X, y = df.drop(\"remarquable\", axis=1), df[\"remarquable\"]\n",
    "X.drop(dropped_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circonference_cm    184\n",
      "hauteur_m           184\n",
      "dtype: int64\n",
      "circonference_cm    136855\n",
      "hauteur_m           136855\n",
      "dtype: int64\n",
      "circonference_cm    0.001344\n",
      "hauteur_m           0.001344\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,  random_state=42)\n",
    "log_reg = LogisticRegression()\n",
    "uder_sample = RandomUnderSampler()\n",
    "X_train, y_train = uder_sample.fit_resample(X_train, y_train)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(X[y==1].count())\n",
    "print(X[y==0].count())\n",
    "print(X[y==1].count() / X[y==0].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8659272231951741\n",
      "precision:  0.006324539212143115\n",
      "recall:  0.7291666666666666\n",
      "f1_score:  0.012540308133285561\n"
     ]
    }
   ],
   "source": [
    "def print_scores(y_true, y_pred):\n",
    "    acc_score = accuracy_score(y_true, y_pred)\n",
    "    print(\"accuracy: \",acc_score)\n",
    "    pre_score = precision_score(y_true, y_pred)\n",
    "    print(\"precision: \",pre_score)\n",
    "    rec_score = recall_score(y_true, y_pred)\n",
    "    print(\"recall: \",rec_score)\n",
    "    f_score = f1_score(y_true, y_pred)\n",
    "    print(\"f1_score: \",f_score)\n",
    "\n",
    "\n",
    "print_scores(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It does not work ... why ?\n",
    "\n",
    "The prediction of remarquable three can't work because first of all because of the dataset size.  \n",
    "it is a 13k instances dataset, with only 138 remarquable three. If we under sample it or over sample it, it will over predict threes (because we don't have a 99,9% correlation with our cols).  \n",
    "We will assume that the 138 threes are the chosen one by the 200k instances of the datasets, and all the unlabelized are not remarquable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
